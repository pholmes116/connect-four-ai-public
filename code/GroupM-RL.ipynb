{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ST449 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect4 Best Bots and Modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import sys\n",
    "import pygame\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import namedtuple, defaultdict, deque\n",
    "import time\n",
    "import multiprocessing\n",
    "# from aima_python_master.utils4e  import *\n",
    "# from aima_python_master.games4e  import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Connect Four Game class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GameState = namedtuple('GameState', 'to_move, utility, board, moves')\n",
    "\n",
    "class Game:\n",
    "    \"\"\"A game is similar to a problem, but it has a utility for each\n",
    "    state and a terminal test instead of a path cost and a goal\n",
    "    test. To create a game, subclass this class and implement actions,\n",
    "    result, utility, and terminal_test. You may override display and\n",
    "    successors or you can inherit their default methods. You will also\n",
    "    need to set the .initial attribute to the initial state; this can\n",
    "    be done in the constructor.\"\"\"\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\"Return a list of the allowable moves at this point.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def result(self, state, move):\n",
    "        \"\"\"Return the state that results from making a move from a state.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def utility(self, state, player):\n",
    "        \"\"\"Return the value of this final state to player.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def terminal_test(self, state):\n",
    "        \"\"\"Return True if this is a final state for the game.\"\"\"\n",
    "        return not self.actions(state)\n",
    "\n",
    "    def to_move(self, state):\n",
    "        \"\"\"Return the player whose move it is in this state.\"\"\"\n",
    "        return state.to_move\n",
    "\n",
    "    def display(self, state):\n",
    "        \"\"\"Print or otherwise display the state.\"\"\"\n",
    "        print(state)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<{}>'.format(self.__class__.__name__)\n",
    "\n",
    "    def play_game(self, *players):\n",
    "        \"\"\"Play an n-person, move-alternating game.\"\"\"\n",
    "        state = self.initial\n",
    "        while True:\n",
    "            for player in players:\n",
    "                move = player(self, state)\n",
    "                state = self.result(state, move)\n",
    "                if self.terminal_test(state):\n",
    "                    self.display(state)\n",
    "                    return self.utility(state, self.to_move(self.initial))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C4(Game):\n",
    "    \"\"\"A TicTacToe-like game in which you can only make a move on the bottom\n",
    "    row, or in a square directly above an occupied square. Traditionally\n",
    "    played on a 6*7 board and requiring 4 in a row.\"\"\"\n",
    "\n",
    "    def __init__(self, h=6, v=7, k=4):\n",
    "        self.h = h\n",
    "        self.v = v\n",
    "        self.k = k\n",
    "        moves = [(x, y) for x in range(1, h + 1)\n",
    "                 for y in range(1, v + 1)]\n",
    "        self.initial = GameState(to_move='X', utility=0, board={}, moves=moves)\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\" If we write (x, y) as the coordinate on the board,\n",
    "        then the bottom row correspond to x=7, or equivalently x=self.h\n",
    "        Recall that state.board is a dict and the keys are occupied locations. \"\"\"\n",
    "        return [(x, y) for (x, y) in state.moves\n",
    "                if x == self.h or (x + 1 , y) in state.board]\n",
    "\n",
    "    def result(self, state, move):\n",
    "        if move not in state.moves:\n",
    "            return state  # Illegal move has no effect\n",
    "        board = state.board.copy()\n",
    "        board[move] = state.to_move\n",
    "        moves = list(state.moves)\n",
    "        moves.remove(move)\n",
    "        return GameState(to_move=('O' if state.to_move == 'X' else 'X'),\n",
    "                         utility=self.compute_utility(board, move, state.to_move),\n",
    "                         board=board, moves=moves)\n",
    "\n",
    "    def utility(self, state, player):\n",
    "        \"\"\"Return the value to player; 1 for win, -1 for loss, 0 otherwise.\"\"\"\n",
    "        return state.utility if player == 'X' else -state.utility\n",
    "\n",
    "    def terminal_test(self, state):\n",
    "        \"\"\"A state is terminal if it is won or there are no empty squares.\"\"\"\n",
    "        return state.utility != 0 or len(state.moves) == 0\n",
    "\n",
    "    def display(self, state):\n",
    "        board = state.board\n",
    "        for x in range(1, self.h + 1):\n",
    "            for y in range(1, self.v + 1):\n",
    "                print(board.get((x, y), '.'), end=' ')\n",
    "            print()\n",
    "\n",
    "    def compute_utility(self, board, move, player):\n",
    "        \"\"\"If 'X' wins with this move, return 1; if 'O' wins return -1; else return 0.\"\"\"\n",
    "        if (self.k_in_row(board, move, player, (0, 1)) or\n",
    "                self.k_in_row(board, move, player, (1, 0)) or\n",
    "                self.k_in_row(board, move, player, (1, -1)) or\n",
    "                self.k_in_row(board, move, player, (1, 1))):\n",
    "            return +1 if player == 'X' else -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def k_in_row(self, board, move, player, delta_x_y):\n",
    "        \"\"\"Return true if there is a line through move on board for player.\"\"\"\n",
    "        (delta_x, delta_y) = delta_x_y\n",
    "        x, y = move\n",
    "        n = 0  # n is number of moves in row\n",
    "        while board.get((x, y)) == player:\n",
    "            n += 1\n",
    "            x, y = x + delta_x, y + delta_y\n",
    "        x, y = move\n",
    "        while board.get((x, y)) == player:\n",
    "            n += 1\n",
    "            x, y = x - delta_x, y - delta_y\n",
    "        n -= 1  # Because we counted move itself twice\n",
    "        return n >= self.k\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_segments(h=6, v=7, k=4):\n",
    "    \"\"\" generate all segments of length k=4 on this board;\n",
    "        segment is a list of lists of length 4 \"\"\"\n",
    "    segments = []\n",
    "\n",
    "    # generate the vertical segments\n",
    "    for y in range(1, v + 1):\n",
    "        for x in range(1, h - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x + t, y))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the horizontal segments\n",
    "    for x in range(1, h + 1):\n",
    "        for y in range(1, v - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the bottom left to top right diagonal segments\n",
    "    for x in range(k, h + 1):\n",
    "        for y in range(1, v - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x - t, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the top left to bottom right diagonal segments\n",
    "    for y in range(1, v - k + 2):\n",
    "        for x in range(1, h - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x + t, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    return segments\n",
    "\n",
    "all_segments = generate_segments()\n",
    "\n",
    "def count_in_segment(segment, state):\n",
    "    \"\"\"  Returns the count of 1's & 2's in a segment \"\"\"\n",
    "    \"\"\"  Returns the count of X's & O's in a segment \"\"\"\n",
    "    X_count, O_count = 0, 0\n",
    "    for x, y in segment:\n",
    "        if state.board.get((x, y)) == 'X':\n",
    "            X_count += 1\n",
    "        elif state.board.get((x, y)) == 'O':\n",
    "            O_count += 1\n",
    "    return X_count, O_count\n",
    "\n",
    "def eval_segment(segment, state, player):\n",
    "    \"\"\" Returns the evaluation score for a segment \"\"\"\n",
    "    X_count, O_count = count_in_segment(segment, state)\n",
    "    if X_count > 0 and O_count > 0:\n",
    "        return 0   # mixed segments are neutral\n",
    "\n",
    "    count = max(X_count, O_count)\n",
    "    score = 0\n",
    "\n",
    "    if count == 1:  # open segments with 1 in a row (small chance)\n",
    "        score = 1\n",
    "    elif count == 2:  # open segments with 2 in a row (medium chance)\n",
    "        score = 10\n",
    "    elif count == 3:  # open segments with 3 in a row (big chance)\n",
    "        score = 100\n",
    "    elif count == 4:   # open segments with 4 in a row (game over)\n",
    "        score = 100000\n",
    "\n",
    "    if X_count > O_count:\n",
    "        dominant = 'X'\n",
    "    else:\n",
    "        dominant = 'O'\n",
    "\n",
    "    if dominant == player:\n",
    "        return score\n",
    "    else:\n",
    "        return -score\n",
    "\n",
    "def eval_fn(state, player):\n",
    "    \"\"\" The evaluation function \"\"\"\n",
    "    total = 0\n",
    "    for segment in all_segments:\n",
    "        total += eval_segment(segment, state, player)\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alpha-beta cutoff search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_beta_cutoff_search(state, game, d=4, cutoff_test=None, eval_fn=None):\n",
    "    \"\"\"Search game to determine best action; use alpha-beta pruning.\n",
    "    This version cuts off search and uses an evaluation function.\"\"\"\n",
    "\n",
    "    player = game.to_move(state)\n",
    "\n",
    "    # Functions used by alpha_beta\n",
    "    def max_value(state, alpha, beta, depth):\n",
    "        if cutoff_test(state, depth):\n",
    "            return eval_fn(state, player)\n",
    "        v = -np.inf\n",
    "        for a in game.actions(state):\n",
    "            v = max(v, min_value(game.result(state, a), alpha, beta, depth + 1))\n",
    "            if v >= beta:\n",
    "                return v\n",
    "            alpha = max(alpha, v)\n",
    "        return v\n",
    "\n",
    "    def min_value(state, alpha, beta, depth):\n",
    "        if cutoff_test(state, depth):\n",
    "            return eval_fn(state, player)\n",
    "        v = np.inf\n",
    "        for a in game.actions(state):\n",
    "            v = min(v, max_value(game.result(state, a), alpha, beta, depth + 1))\n",
    "            if v <= alpha:\n",
    "                return v\n",
    "            beta = min(beta, v)\n",
    "        return v\n",
    "\n",
    "    # Body of alpha_beta_cutoff_search starts here:\n",
    "    # The default test cuts off at depth d or at a terminal state\n",
    "    cutoff_test = (cutoff_test or (lambda state, depth: depth > d or game.terminal_test(state)))\n",
    "    eval_fn = eval_fn or (lambda state, player: game.utility(state, player))\n",
    "    best_score = -np.inf\n",
    "    beta = np.inf\n",
    "    best_action = None\n",
    "    for a in game.actions(state):\n",
    "        v = min_value(game.result(state, a), best_score, beta, 1)\n",
    "        if v > best_score:\n",
    "            best_score = v\n",
    "            best_action = a\n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monte Carlo tree search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCT_Node:\n",
    "    \"\"\"Node in the Monte Carlo search tree, keeps track of the children states.\"\"\"\n",
    "\n",
    "    def __init__(self, parent=None, state=None, U=0, N=0):\n",
    "        self.__dict__.update(parent=parent, state=state, U=U, N=N)\n",
    "        self.children = {}\n",
    "        self.actions = None\n",
    "\n",
    "\n",
    "def ucb(n, C=1.4):\n",
    "    return np.inf if n.N == 0 else n.U / n.N + C * np.sqrt(np.log(n.parent.N) / n.N)\n",
    "\n",
    "def monte_carlo_tree_search(state, game, N=20000):\n",
    "    def select(n):\n",
    "        \"\"\"select a leaf node in the tree\"\"\"\n",
    "        if n.children:\n",
    "            return select(max(n.children.keys(), key=ucb))\n",
    "        else:\n",
    "            return n\n",
    "\n",
    "    def expand(n):\n",
    "        \"\"\"expand the leaf node by adding all its children states\"\"\"\n",
    "        if not n.children and not game.terminal_test(n.state):\n",
    "            n.children = {MCT_Node(state=game.result(n.state, action), parent=n): action\n",
    "                          for action in game.actions(n.state)}\n",
    "        return select(n)\n",
    "\n",
    "    def simulate(game, state):\n",
    "        \"\"\"simulate the utility of current state by random picking a step\"\"\"\n",
    "        player = game.to_move(state)\n",
    "        while not game.terminal_test(state):\n",
    "            action = random.choice(list(game.actions(state)))\n",
    "            state = game.result(state, action)\n",
    "        v = game.utility(state, player)\n",
    "        return -v\n",
    "\n",
    "    def backprop(n, utility):\n",
    "        \"\"\"passing the utility back to all parent nodes\"\"\"\n",
    "        if utility > 0:\n",
    "            n.U += utility\n",
    "        # if utility == 0:\n",
    "        #     n.U += 0.5\n",
    "        n.N += 1\n",
    "        if n.parent:\n",
    "            backprop(n.parent, -utility)\n",
    "\n",
    "    root = MCT_Node(state=state)\n",
    "\n",
    "    for _ in range(N):\n",
    "        leaf = select(root)\n",
    "        child = expand(leaf)\n",
    "        result = simulate(game, child.state)\n",
    "        backprop(child, result)\n",
    "\n",
    "    max_state = max(root.children, key=lambda p: p.N)\n",
    "\n",
    "    return root.children.get(max_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_MC_bot(game, state):\n",
    "    return monte_carlo_tree_search(state, game, N = 1000)\n",
    "\n",
    "def standard_alpha_beta_bot(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 5)\n",
    "\n",
    "def standard_alpha_beta_eval_bot(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 5, eval_fn = eval_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testC4game = C4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#players = [test_MC_bot]\n",
    "\n",
    "number_of_games = 100 \n",
    "\n",
    "def test_MC_bot_1000(game, state):\n",
    "    return monte_carlo_tree_search(state, game, N = 1000)\n",
    "\n",
    "def test_MC_bot_10000(game, state):\n",
    "    return monte_carlo_tree_search(state, game, N = 10000)\n",
    "\n",
    "def test_MC_bot_5000(game, state):\n",
    "    return monte_carlo_tree_search(state, game, N = 5000)\n",
    "\n",
    "def test_alpha_beta_bot_3(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 3)\n",
    "\n",
    "def test_alpha_beta_bot_4(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 4)\n",
    "\n",
    "def test_alpha_beta_bot_5(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 5)\n",
    "\n",
    "def test_alpha_beta_eval_bot_3(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 3, eval_fn = eval_fn)\n",
    "\n",
    "def test_alpha_beta_eval_bot_4(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 4, eval_fn = eval_fn)\n",
    "\n",
    "def test_alpha_beta_eval_bot_5(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 5, eval_fn = eval_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Function to calculate heuristic score\n",
    "def calculate_heuristic(wins, total_time):\n",
    "    return wins / total_time if total_time > 0 else 0\n",
    "\n",
    "# Simulation cache and results DataFrame\n",
    "simulation_cache = {}\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    \"Bot1\", \"Bot2\", \"Bot1_Wins\", \"Bot2_Wins\", \"Bot1_Time\", \"Bot2_Time\", \"Bot1_Heuristic\", \"Bot2_Heuristic\"\n",
    "])\n",
    "\n",
    "# Function to run simulation and calculate heuristic scores\n",
    "def run_simulation_and_calculate_scores(bot1, bot2, num_games=30):\n",
    "    bot_pair_key = (bot1[1], bot2[1])  # Use bot labels as cache key\n",
    "\n",
    "    # Check if results are already cached\n",
    "    if bot_pair_key in simulation_cache:\n",
    "        return simulation_cache[bot_pair_key]\n",
    "\n",
    "    results = {\"bot1_wins\": 0, \"bot2_wins\": 0, \"bot1_time\": 0, \"bot2_time\": 0}\n",
    "\n",
    "    # Each bot alternates as the starting player for half the games\n",
    "    for i in range(num_games):\n",
    "        if i % 2 == 0:\n",
    "            game_results = run_simulation(1, [(bot1[0], bot1[1]), (bot2[0], bot2[1])])\n",
    "        else:\n",
    "            game_results = run_simulation(1, [(bot2[0], bot2[1]), (bot1[0], bot1[1])])\n",
    "\n",
    "        results[\"bot1_wins\"] += game_results[bot1[1]][\"wins\"]\n",
    "        results[\"bot2_wins\"] += game_results[bot2[1]][\"wins\"]\n",
    "        results[\"bot1_time\"] += game_results[bot1[1]][\"time_per_move\"]\n",
    "        results[\"bot2_time\"] += game_results[bot2[1]][\"time_per_move\"]\n",
    "\n",
    "    bot1_heuristic = calculate_heuristic(results[\"bot1_wins\"], results[\"bot1_time\"])\n",
    "    bot2_heuristic = calculate_heuristic(results[\"bot2_wins\"], results[\"bot2_time\"])\n",
    "\n",
    "    # Cache the results\n",
    "    simulation_cache[bot_pair_key] = (bot1_heuristic, bot2_heuristic)\n",
    "\n",
    "    # Append results to DataFrame\n",
    "    results_df.loc[len(results_df)] = [\n",
    "        bot1[1], bot2[1],\n",
    "        results[\"bot1_wins\"], results[\"bot2_wins\"],\n",
    "        results[\"bot1_time\"], results[\"bot2_time\"],\n",
    "        bot1_heuristic, bot2_heuristic\n",
    "    ]\n",
    "    \n",
    "    return bot1_heuristic, bot2_heuristic\n",
    "\n",
    "# Function to create heuristic matrix and format as DataFrame\n",
    "def create_heuristic_matrix_df(bots, opponents):\n",
    "    bot_names = [bot[1] for bot in bots]\n",
    "    opponent_names = [opponent[1] for opponent in opponents]\n",
    "\n",
    "    # Initialize matrix with zeros\n",
    "    matrix = np.zeros((len(bots), len(opponents) + 1))\n",
    "\n",
    "    for i, bot in enumerate(bots):\n",
    "        total_heuristic = 0\n",
    "        for j, opponent in enumerate(opponents):\n",
    "            if bot != opponent:\n",
    "                bot_heuristic, _ = run_simulation_and_calculate_scores(bot, opponent)\n",
    "                matrix[i, j] = bot_heuristic\n",
    "                total_heuristic += bot_heuristic\n",
    "\n",
    "        # Calculate average heuristic score\n",
    "        if len(opponents) > 0:\n",
    "            matrix[i, -1] = total_heuristic / len(opponents)\n",
    "\n",
    "    # Create DataFrame with column headers\n",
    "    column_headers = opponent_names + [\"Average\"]\n",
    "    heuristic_df = pd.DataFrame(matrix, columns=column_headers)\n",
    "    heuristic_df.insert(0, \"Bot\", bot_names)  # Insert bot names as the first column\n",
    "\n",
    "    return heuristic_df\n",
    "\n",
    "# Function to run a simulation of games\n",
    "def run_simulation(num_games, bot_functions_with_labels):\n",
    "    results = {label: {\"wins\": 0, \"total_time\": 0, \"total_moves\": 0} for _, label in bot_functions_with_labels}\n",
    "    bot_order = deque([bot for bot, _ in bot_functions_with_labels])\n",
    "    label_order = deque([label for _, label in bot_functions_with_labels])\n",
    "\n",
    "    for i in range(num_games):\n",
    "        bot_order.rotate(-1)\n",
    "        label_order.rotate(-1)\n",
    "        X_bot, O_bot = bot_order\n",
    "        X_label, O_label = label_order\n",
    "        game = C4(h=6, v=7, k=4)\n",
    "        state = game.initial\n",
    "        current_player = 'X'\n",
    "        game_over = False\n",
    "        player_to_bot = {'X': X_bot, 'O': O_bot}\n",
    "        player_to_label = {'X': X_label, 'O': O_label}\n",
    "\n",
    "        while not game_over:\n",
    "            bot = player_to_bot[current_player]\n",
    "            start_time = time.time()\n",
    "            move = bot(game, state)\n",
    "            state = game.result(state, move)\n",
    "            move_time = time.time() - start_time\n",
    "            bot_label = player_to_label[current_player]\n",
    "            results[bot_label][\"total_time\"] += move_time\n",
    "            results[bot_label][\"total_moves\"] += 1\n",
    "\n",
    "            if game.terminal_test(state):\n",
    "                winner = game.utility(state, game.to_move(game.initial))\n",
    "                if winner == 1:\n",
    "                    results[X_label][\"wins\"] += 1\n",
    "                elif winner == -1:\n",
    "                    results[O_label][\"wins\"] += 1\n",
    "                game_over = True\n",
    "\n",
    "            current_player = 'O' if current_player == 'X' else 'X'\n",
    "\n",
    "    for bot in results:\n",
    "        if results[bot][\"total_moves\"] > 0:\n",
    "            results[bot][\"time_per_move\"] = results[bot][\"total_time\"] / results[bot][\"total_moves\"]\n",
    "        else:\n",
    "            results[bot][\"time_per_move\"] = 0\n",
    "\n",
    "    return results\n",
    "\n",
    "# Define the bots\n",
    "monte_carlo_bots = [\n",
    "    (test_MC_bot_1000, \"MC_1000\"),\n",
    "    (test_MC_bot_10000, \"MC_10000\"),\n",
    "    (test_MC_bot_5000, \"MC_5000\")\n",
    "]\n",
    "\n",
    "alpha_beta_bots = [\n",
    "    (test_alpha_beta_bot_4, \"AB_4\"),\n",
    "    (test_alpha_beta_bot_5, \"AB_5\"),\n",
    "    (test_alpha_beta_eval_bot_3, \"AB_3\")\n",
    "]\n",
    "\n",
    "alpha_beta_eval_bots = [\n",
    "    (test_alpha_beta_eval_bot_4, \"ABE_4\"),\n",
    "    (test_alpha_beta_eval_bot_5, \"ABE_5\"),\n",
    "    (test_alpha_beta_eval_bot_3, \"ABE_3\")\n",
    "]\n",
    "\n",
    "# Create matrices for each type of bots\n",
    "monte_carlo_df = create_heuristic_matrix_df(monte_carlo_bots, alpha_beta_bots + alpha_beta_eval_bots)\n",
    "alpha_beta_df = create_heuristic_matrix_df(alpha_beta_bots, monte_carlo_bots + alpha_beta_eval_bots)\n",
    "alpha_beta_eval_df = create_heuristic_matrix_df(alpha_beta_eval_bots, monte_carlo_bots + alpha_beta_bots)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nMonte Carlo Bots Heuristic Matrix:\")\n",
    "print(monte_carlo_df)\n",
    "\n",
    "print(\"\\nAlpha Beta Bots Heuristic Matrix:\")\n",
    "print(alpha_beta_df)\n",
    "\n",
    "print(\"\\nAlpha Beta Eval Bots Heuristic Matrix:\")\n",
    "print(alpha_beta_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different sized boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_test = 6 # height of the new board\n",
    "v_test = 10 # width of the new board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically update the utility function used for evaluation in the alpha_beta_eval_bot to account for different sized boards\n",
    "def generate_segments_diff_size(h=h_test, v=v_test, k=4):\n",
    "    \"\"\" generate all segments of length k=4 on this board;\n",
    "        segment is a list of lists of length 4 \"\"\"\n",
    "    segments = []\n",
    "\n",
    "    # generate the vertical segments\n",
    "    for y in range(1, v + 1):\n",
    "        for x in range(1, h - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x + t, y))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the horizontal segments\n",
    "    for x in range(1, h + 1):\n",
    "        for y in range(1, v - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the bottom left to top right diagonal segments\n",
    "    for x in range(k, h + 1):\n",
    "        for y in range(1, v - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x - t, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the top left to bottom right diagonal segments\n",
    "    for y in range(1, v - k + 2):\n",
    "        for x in range(1, h - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x + t, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    return segments\n",
    "\n",
    "all_segments_diff_size = generate_segments_diff_size()\n",
    "\n",
    "def count_in_segment_diff_size(segment, state):\n",
    "    \"\"\"  Returns the count of 1's & 2's in a segment \"\"\"\n",
    "    \"\"\"  Returns the count of X's & O's in a segment \"\"\"\n",
    "    X_count, O_count = 0, 0\n",
    "    for x, y in segment:\n",
    "        if state.board.get((x, y)) == 'X':\n",
    "            X_count += 1\n",
    "        elif state.board.get((x, y)) == 'O':\n",
    "            O_count += 1\n",
    "    return X_count, O_count\n",
    "\n",
    "def eval_segment_diff_size(segment, state, player):\n",
    "    \"\"\" Returns the evaluation score for a segment \"\"\"\n",
    "    X_count, O_count = count_in_segment_diff_size(segment, state)\n",
    "    if X_count > 0 and O_count > 0:\n",
    "        return 0   # mixed segments are neutral\n",
    "\n",
    "    count = max(X_count, O_count)\n",
    "    score = 0\n",
    "\n",
    "    if count == 1:  # open segments with 1 in a row (small chance)\n",
    "        score = 1\n",
    "    elif count == 2:  # open segments with 2 in a row (medium chance)\n",
    "        score = 10\n",
    "    elif count == 3:  # open segments with 3 in a row (big chance)\n",
    "        score = 100\n",
    "    elif count == 4:   # open segments with 4 in a row (game over)\n",
    "        score = 100000\n",
    "\n",
    "    if X_count > O_count:\n",
    "        dominant = 'X'\n",
    "    else:\n",
    "        dominant = 'O'\n",
    "\n",
    "    if dominant == player:\n",
    "        return score\n",
    "    else:\n",
    "        return -score\n",
    "\n",
    "def eval_fn_diff_size(state, player):\n",
    "    \"\"\" The evaluation function \"\"\"\n",
    "    total = 0\n",
    "    for segment in all_segments_diff_size:\n",
    "        total += eval_segment_diff_size(segment, state, player)\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testC4game_diff_size = C4(h = h_test, v = v_test)\n",
    "\n",
    "def diff_size_MC_bot(game, state):\n",
    "    return monte_carlo_tree_search(state, game, N = 1000)\n",
    "\n",
    "def diff_size_alpha_beta_bot(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 5)\n",
    "\n",
    "def diff_size_alpha_beta_eval_bot(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 5, eval_fn = eval_fn_diff_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testC4game_diff_size.play_game(diff_size_MC_bot, diff_size_alpha_beta_eval_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will all be in a loop, testing various values for 'h' and 'v' both in the initialization of the C4() class,\n",
    "## and in the generation of the evaluation function for alpha_beta_eval_bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C4_3_player(Game):\n",
    "    \"\"\"\n",
    "    A TicTacToe-like game in which you can only make a move on the bottom\n",
    "    row, or in a square directly above an occupied square. This game introduces a third player that will play, the players take turns sequentially 1,2,3\n",
    "    \"\"\"\n",
    "\n",
    "    # def __init__(self, h=3, v=3, k=3):\n",
    "    def __init__(self, h=6, v=7, k=4):\n",
    "        self.h = h\n",
    "        self.v = v\n",
    "        self.k = k\n",
    "        moves = [(x, y) for x in range(1, h + 1)\n",
    "                 for y in range(1, v + 1)]\n",
    "        self.initial = GameState(to_move='X', utility=0, board={}, moves=moves)\n",
    "\n",
    "    def actions(self, state):\n",
    "        # \"\"\"Legal moves are any square not yet taken.\"\"\"\n",
    "        \"\"\" If we write (x, y) as the coordinate on the board,\n",
    "        then the bottom row correspond to x=7, or equivalently x=self.h\n",
    "        Recall that state.board is a dict and the keys are occupied locations. \"\"\"\n",
    "        # return state.moves\n",
    "        return [(x, y) for (x, y) in state.moves\n",
    "                if x == self.h or (x + 1 , y) in state.board]\n",
    "\n",
    "    def result(self, state, move):\n",
    "        \"\"\"Apply a move and return the new state.\"\"\"\n",
    "        if move not in state.moves:\n",
    "            return state  # Illegal move has no effect\n",
    "        board = state.board.copy()\n",
    "        board[move] = state.to_move\n",
    "        moves = list(state.moves)\n",
    "        moves.remove(move)\n",
    "\n",
    "        # Determine the next player\n",
    "        next_player = self.get_next_player(state.to_move)\n",
    "\n",
    "        return GameState(to_move=next_player,\n",
    "                         utility=self.compute_utility(board, move, state.to_move),\n",
    "                         board=board, moves=moves)\n",
    "\n",
    "    def utility(self, state, player):\n",
    "        \"\"\"Return the utility value for the given player.\"\"\"\n",
    "        if state.utility == 1:  # Player 1 (X) wins\n",
    "            return 1 if player == 'X' else -1\n",
    "        elif state.utility == -1:  # Player 2 (O) wins\n",
    "            return 1 if player == 'O' else -1\n",
    "        elif state.utility == 2:  # Player 3 (3) wins\n",
    "            return 2 if player == '3' else -2\n",
    "        return 0  # No winner yet\n",
    "    \n",
    "\n",
    "    def terminal_test(self, state):\n",
    "        \"\"\"A state is terminal if it is won or there are no empty squares.\"\"\"\n",
    "        return state.utility != 0 or len(state.moves) == 0\n",
    "\n",
    "    def display(self, state):\n",
    "        board = state.board\n",
    "        for x in range(1, self.h + 1):\n",
    "            for y in range(1, self.v + 1):\n",
    "                print(board.get((x, y), '.'), end=' ')\n",
    "            print()\n",
    "\n",
    "    def compute_utility(self, board, move, player):\n",
    "        \"\"\"If a player wins with this move, return a specific utility.\"\"\"\n",
    "        if (self.k_in_row(board, move, player, (0, 1)) or  # Horizontal\n",
    "                self.k_in_row(board, move, player, (1, 0)) or  # Vertical\n",
    "                self.k_in_row(board, move, player, (1, -1)) or  # Diagonal /\n",
    "                self.k_in_row(board, move, player, (1, 1))):  # Diagonal \\\n",
    "            if player == 'X':\n",
    "                return 1  # X wins\n",
    "            elif player == 'O':\n",
    "                return -1  # O wins\n",
    "            elif player == '3':\n",
    "                return 2  # Player 3 wins\n",
    "        return 0  # No winner\n",
    "\n",
    "\n",
    "    def k_in_row(self, board, move, player, delta_x_y):\n",
    "        \"\"\"Return true if there is a line through move on board for player.\"\"\"\n",
    "        (delta_x, delta_y) = delta_x_y\n",
    "        x, y = move\n",
    "        n = 0  # n is number of moves in row\n",
    "        while board.get((x, y)) == player:\n",
    "            n += 1\n",
    "            x, y = x + delta_x, y + delta_y\n",
    "        x, y = move\n",
    "        while board.get((x, y)) == player:\n",
    "            n += 1\n",
    "            x, y = x - delta_x, y - delta_y\n",
    "        n -= 1  # Because we counted move itself twice\n",
    "        return n >= self.k\n",
    "    \n",
    "    def get_next_player(self, current_player):\n",
    "        \"\"\"Cycle through the three players: X -> O -> 3 -> X.\"\"\"\n",
    "        return {'X': 'O', 'O': '3', '3': 'X'}[current_player]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval Function For 3 Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_segments_3_player(h=6, v=7, k=4):\n",
    "    \"\"\" generate all segments of length k=4 on this board;\n",
    "        segment is a list of lists of length 4 \"\"\"\n",
    "    segments = []\n",
    "\n",
    "    # generate the vertical segments\n",
    "    for y in range(1, v + 1):\n",
    "        for x in range(1, h - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x + t, y))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the horizontal segments\n",
    "    for x in range(1, h + 1):\n",
    "        for y in range(1, v - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the bottom left to top right diagonal segments\n",
    "    for x in range(k, h + 1):\n",
    "        for y in range(1, v - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x - t, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the top left to bottom right diagonal segments\n",
    "    for y in range(1, v - k + 2):\n",
    "        for x in range(1, h - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x + t, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    return segments\n",
    "\n",
    "all_segments_three = generate_segments_3_player()\n",
    "\n",
    "def count_in_segment_three(segment, state):\n",
    "    \"\"\"  Returns the count of 1's & 2's in a segment \"\"\"\n",
    "    \"\"\"  Returns the count of X's & O's in a segment \"\"\"\n",
    "    X_count, O_count, three_count = 0, 0, 0\n",
    "    for x, y in segment:\n",
    "        if state.board.get((x, y)) == 'X':\n",
    "            X_count += 1\n",
    "        elif state.board.get((x, y)) == 'O':\n",
    "            O_count += 1\n",
    "        elif state.board.get((x, y)) == '3':\n",
    "            three_count += 1\n",
    "    return X_count, O_count, three_count\n",
    "\n",
    "def eval_segment_three(segment, state, player):\n",
    "    \"\"\" Returns the evaluation score for a segment \"\"\"\n",
    "    X_count, O_count, three_count = count_in_segment_three(segment, state)\n",
    "    if (X_count > 0 and O_count > 0) or (X_count > 0 and three_count >0) or (O_count > 0 and three_count > 0):\n",
    "        return 0   # mixed segments are neutral\n",
    "\n",
    "    count = max(X_count, O_count, three_count)\n",
    "    score = 0\n",
    "\n",
    "    if count == 1:  # open segments with 1 in a row (small chance)\n",
    "        score = 1\n",
    "    elif count == 2:  # open segments with 2 in a row (medium chance)\n",
    "        score = 10\n",
    "    elif count == 3:  # open segments with 3 in a row (big chance)\n",
    "        score = 100\n",
    "    elif count == 4:   # open segments with 4 in a row (game over)\n",
    "        score = 100000\n",
    "\n",
    "    if (X_count > O_count) and (X_count > three_count):\n",
    "        dominant = 'X'\n",
    "    elif (O_count > three_count) and (O_count > X_count):\n",
    "        dominant = 'O'\n",
    "    else:\n",
    "        dominant = '3'\n",
    "        \n",
    "    if dominant == player:\n",
    "        return score\n",
    "    else:\n",
    "        return -score\n",
    "\n",
    "def eval_fn_three(state, player):\n",
    "    \"\"\" The evaluation function \"\"\"\n",
    "    total = 0\n",
    "    for segment in all_segments_three:\n",
    "        total += eval_segment_three(segment, state, player)\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ucb(n, C=1.4):\n",
    "    return np.inf if n.N == 0 else n.U / n.N + C * np.sqrt(np.log(n.parent.N) / n.N)\n",
    "\n",
    "def monte_carlo_tree_search_three(state, game, N=20000):\n",
    "    def select(n):\n",
    "        \"\"\"Select a leaf node in the tree\"\"\"\n",
    "        if n.children:\n",
    "            return select(max(n.children.keys(), key=ucb))\n",
    "        else:\n",
    "            return n\n",
    "\n",
    "    def expand(n):\n",
    "        \"\"\"Expand the leaf node by adding all its children states\"\"\"\n",
    "        if not n.children and not game.terminal_test(n.state):\n",
    "            n.children = {MCT_Node(state=game.result(n.state, action), parent=n): action\n",
    "                          for action in game.actions(n.state)}\n",
    "        return select(n)\n",
    "\n",
    "    def simulate(game, state):\n",
    "        \"\"\"Simulate the utility of current state by random picking a step\"\"\"\n",
    "        player = game.to_move(state)\n",
    "        while not game.terminal_test(state):\n",
    "            action = random.choice(list(game.actions(state)))\n",
    "            state = game.result(state, action)\n",
    "            player = game.to_move(state)  # Update the player turn after each action\n",
    "        v = game.utility(state, player)  # Evaluate the utility for the current player\n",
    "        return -v  # Assume the utility for the player is returned\n",
    "\n",
    "    def backprop(n, utility, player):\n",
    "        \"\"\"Passing the utility back to all parent nodes\"\"\"\n",
    "        if utility > 0:\n",
    "            n.U += utility\n",
    "        n.N += 1\n",
    "        if n.parent:\n",
    "            backprop(n.parent, -utility, player)\n",
    "\n",
    "    root = MCT_Node(state=state)\n",
    "\n",
    "    for _ in range(N):\n",
    "        leaf = select(root)\n",
    "        child = expand(leaf)\n",
    "        result = simulate(game, child.state)\n",
    "        backprop(child, result, game.to_move(child.state))  # Propagate with the correct player\n",
    "\n",
    "    max_state = max(root.children, key=lambda p: p.N)\n",
    "\n",
    "    return root.children.get(max_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_MC_bot_three(game, state):\n",
    "    return monte_carlo_tree_search_three(state, game, N = 1000)\n",
    "\n",
    "def test_alpha_beta_bot_three(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 5)\n",
    "\n",
    "def test_alpha_beta_eval_bot_three(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 5, eval_fn = eval_fn_three)\n",
    "\n",
    "# def random_bot(game, state):\n",
    "#     return random.choice\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testC4game_3 = C4_3_player()\n",
    "testC4game_3.play_game(test_MC_bot_three, test_alpha_beta_eval_bot_three, test_alpha_beta_bot_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import deque, defaultdict\n",
    "from itertools import permutations\n",
    "\n",
    "def run_simulation(num_games, bot_functions_with_labels):\n",
    "    \"\"\"\n",
    "    Run a simulation of games, alternating which bot goes first, second, and third.\n",
    "    The bots are passed along with their custom labels.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_games: The number of games to simulate.\n",
    "    - bot_functions_with_labels: A list of tuples where each tuple contains a bot function and its custom label.\n",
    "    \n",
    "    Returns:\n",
    "    - results: A dictionary with the bot labels as keys, storing the number of wins and average time per move.\n",
    "    \"\"\"\n",
    "    # Initialize results structure for each bot\n",
    "    results = {label: {\"wins\": 0, \"total_time\": 0, \"total_moves\": 0} for _, label in bot_functions_with_labels}\n",
    "\n",
    "    # Generate all permutations of bot positions\n",
    "    bot_permutations = list(permutations(bot_functions_with_labels))\n",
    "    num_permutations = len(bot_permutations)\n",
    "    \n",
    "    # Ensure an equal number of all permutations\n",
    "    games_per_permutation = num_games // num_permutations\n",
    "\n",
    "    for i in range(num_games):\n",
    "        # Determine the current permutation to use\n",
    "        current_permutation = bot_permutations[i % num_permutations]\n",
    "\n",
    "        # Assign bots to positions (X, O, 3)\n",
    "        X_bot, O_bot, T_bot = [bot for bot, _ in current_permutation]\n",
    "        X_label, O_label, T_label = [label for _, label in current_permutation]\n",
    "\n",
    "        # Print the player assignments for this game\n",
    "        print(f\"Game {i+1}: X = {X_label}, O = {O_label}, 3 = {T_label}\")\n",
    "\n",
    "        # Now we play the game with X_bot, O_bot, T_bot as players\n",
    "        game = C4_3_player(h=6, v=7, k=4)  # Standard Connect 4 board with 6x7 grid\n",
    "        state = game.initial\n",
    "        \n",
    "        current_player = 'X'\n",
    "        game_over = False\n",
    "        player_to_bot = {'X': X_bot, 'O': O_bot, '3': T_bot}\n",
    "        player_to_label = {'X': X_label, 'O': O_label, '3': T_label}\n",
    "\n",
    "        while not game_over:\n",
    "            # Get the bot for the current player and measure time for the move\n",
    "            bot = player_to_bot[current_player]\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Bot makes a move\n",
    "            move = bot(game, state)  # Assuming this function returns the best move\n",
    "            state = game.result(state, move)  # Apply the move and get the new game state\n",
    "            \n",
    "            move_time = time.time() - start_time\n",
    "            bot_label = player_to_label[current_player]  # Get the label for the current bot\n",
    "            results[bot_label][\"total_time\"] += move_time  # Add time to the corresponding bot\n",
    "            results[bot_label][\"total_moves\"] += 1  # Increment the move count\n",
    "\n",
    "            # Check if the game is over\n",
    "            if game.terminal_test(state):\n",
    "                winner = game.utility(state, game.to_move(game.initial))\n",
    "                if winner == 1:\n",
    "                    results[X_label][\"wins\"] += 1\n",
    "                elif winner == -1:\n",
    "                    results[O_label][\"wins\"] += 1\n",
    "                elif winner == -2:\n",
    "                    results[T_label][\"wins\"] += 1\n",
    "                game_over = True\n",
    "\n",
    "            # Rotate players: X -> O -> 3 -> X\n",
    "            current_player = game.get_next_player(current_player)\n",
    "\n",
    "        # Print the final board state\n",
    "        print(\"Final board state:\")\n",
    "        game.display(state)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    # After all games, calculate average times per move\n",
    "    for bot in results:\n",
    "        if results[bot][\"total_moves\"] > 0:\n",
    "            results[bot][\"time_per_move\"] = results[bot][\"total_time\"] / results[bot][\"total_moves\"]\n",
    "        else:\n",
    "            results[bot][\"time_per_move\"] = 0\n",
    "\n",
    "    return results\n",
    "\n",
    "# Function to display results\n",
    "def display_results(results):\n",
    "    print(\"Simulation Results:\")\n",
    "    for bot, data in results.items():\n",
    "        print(f\"Bot {bot}:\")\n",
    "        print(f\"  Wins: {data['wins']}\")\n",
    "        print(f\"  Average Time per Move: {data['time_per_move']:.4f} seconds\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Running the simulation for n games with any bots\n",
    "bot_functions_with_labels = [\n",
    "    (test_MC_bot_three, \"MCT\"),\n",
    "    (test_alpha_beta_bot, \"AlphaBeta\"),\n",
    "    (test_alpha_beta_eval_bot_three, \"AlphaBetaEval\")\n",
    "]\n",
    "\n",
    "num_games = 6\n",
    "results = run_simulation(num_games, bot_functions_with_labels)\n",
    "\n",
    "# Display the results\n",
    "display_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random \"blocks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C4_obstacles(Game):\n",
    "    \"\"\"A TicTacToe-like game in which you can only make a move on the bottom\n",
    "    row, or in a square directly above an occupied square. Traditionally\n",
    "    played on a 6*7 board and requiring 4 in a row.\"\"\"\n",
    "\n",
    "    def __init__(self, h=6, v=7, k=4, obstacles=None):\n",
    "        self.h = h\n",
    "        self.v = v\n",
    "        self.k = k\n",
    "        self.obstacles = obstacles or [] # List of obstacle positions (x, y)\n",
    "        moves = [(x, y) for x in range(1, h + 1) for y in range(1, v + 1)]\n",
    "        self.initial = GameState(to_move='X', utility=0, board={}, moves=moves)\n",
    "\n",
    "    def actions(self, state):\n",
    "        \"\"\" If we write (x, y) as the coordinate on the board,\n",
    "        then the bottom row correspond to x=7, or equivalently x=self.h\n",
    "        Recall that state.board is a dict and the keys are occupied locations. \"\"\"\n",
    "        valid_moves = []\n",
    "        for (x, y) in state.moves:\n",
    "            if x == self.h and (x, y) not in self.obstacles:\n",
    "                    valid_moves.append((x, y))\n",
    "            elif (x + 1, y) in state.board or (x + 1, y) in self.obstacles:\n",
    "                valid_move = True\n",
    "                for row in range(x + 1, self.h + 1):\n",
    "                    if (row, y) not in state.board and (row, y) not in self.obstacles:\n",
    "                        valid_move = False\n",
    "                        break\n",
    "                if valid_move and (x, y) not in self.obstacles:\n",
    "                    valid_moves.append((x, y))\n",
    "        return valid_moves\n",
    "\n",
    "    def result(self, state, move):\n",
    "        if move not in state.moves:\n",
    "            return state  # Illegal move has no effect\n",
    "        board = state.board.copy()\n",
    "        board[move] = state.to_move\n",
    "        moves = list(state.moves)\n",
    "        moves.remove(move)\n",
    "        return GameState(to_move=('O' if state.to_move == 'X' else 'X'),\n",
    "                         utility=self.compute_utility(board, move, state.to_move),\n",
    "                         board=board, moves=moves)\n",
    "\n",
    "    def utility(self, state, player):\n",
    "        \"\"\"Return the value to player; 1 for win, -1 for loss, 0 otherwise.\"\"\"\n",
    "        return state.utility if player == 'X' else -state.utility\n",
    "\n",
    "    def terminal_test(self, state):\n",
    "        \"\"\"A state is terminal if it is won or there are no empty squares.\"\"\"\n",
    "        return state.utility != 0 or not any(self.actions(state))\n",
    "\n",
    "    def display(self, state):\n",
    "        board = state.board\n",
    "        for x in range(1, self.h + 1):\n",
    "            for y in range(1, self.v + 1):\n",
    "                if (x, y) in self.obstacles:\n",
    "                    print('#', end=' ') # Display the obstacles as '#'s\n",
    "                else:\n",
    "                    print(board.get((x, y), '.'), end=' ')\n",
    "            print()\n",
    "\n",
    "    def compute_utility(self, board, move, player):\n",
    "        \"\"\"If 'X' wins with this move, return 1; if 'O' wins return -1; else return 0.\"\"\"\n",
    "        if (self.k_in_row(board, move, player, (0, 1)) or\n",
    "                self.k_in_row(board, move, player, (1, 0)) or\n",
    "                self.k_in_row(board, move, player, (1, -1)) or\n",
    "                self.k_in_row(board, move, player, (1, 1))):\n",
    "            return + 1 if player == 'X' else -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def k_in_row(self, board, move, player, delta_x_y):\n",
    "        \"\"\"Return true if there is a line through move on board for player.\"\"\"\n",
    "        (delta_x, delta_y) = delta_x_y\n",
    "        x, y = move\n",
    "        n = 0  # n is number of moves in row\n",
    "        while (x, y) in board and board.get((x, y)) == player:\n",
    "            n += 1\n",
    "            x, y = x + delta_x, y + delta_y\n",
    "        x, y = move\n",
    "        while (x, y) in board and board.get((x, y)) == player:\n",
    "            n += 1\n",
    "            x, y = x - delta_x, y - delta_y\n",
    "        n -= 1  # Because we counted move itself twice\n",
    "        return n >= self.k\n",
    "\n",
    "    def play_game(self, *players):\n",
    "        \"\"\"Play an n-person, move-alternating game.\"\"\"\n",
    "        state = self.initial\n",
    "        while True:\n",
    "            for player in players:\n",
    "                move = player(self, state)\n",
    "                state = self.result(state, move)\n",
    "                if self.terminal_test(state):\n",
    "                    print(state.board)\n",
    "                    self.display(state)\n",
    "                    return self.utility(state, self.to_move(self.initial))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically update the utility function used for evaluation in the alpha_beta_eval_bot to account for the \"obstacles\"\n",
    "def generate_segments_obstacles(h=6, v=7, k=4):\n",
    "    \"\"\" generate all segments of length k=4 on this board;\n",
    "        segment is a list of lists of length 4 \"\"\"\n",
    "    segments = []\n",
    "\n",
    "    # generate the vertical segments\n",
    "    for y in range(1, v + 1):\n",
    "        for x in range(1, h - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x + t, y))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the horizontal segments\n",
    "    for x in range(1, h + 1):\n",
    "        for y in range(1, v - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the bottom left to top right diagonal segments\n",
    "    for x in range(k, h + 1):\n",
    "        for y in range(1, v - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x - t, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    # generate the top left to bottom right diagonal segments\n",
    "    for y in range(1, v - k + 2):\n",
    "        for x in range(1, h - k + 2):\n",
    "            segment = []\n",
    "            for t in range(k):\n",
    "                segment.append((x + t, y + t))\n",
    "            segments.append(segment)\n",
    "\n",
    "    return segments\n",
    "\n",
    "all_segments_obstacles = generate_segments_obstacles()\n",
    "\n",
    "def count_in_segment_obstacles(segment, state, game):\n",
    "    \"\"\"  Returns the count of 1's & 2's in a segment \"\"\"\n",
    "    \"\"\"  Returns the count of X's & O's in a segment \"\"\"\n",
    "    X_count, O_count, obstacle_count = 0, 0, 0\n",
    "    for x, y in segment:\n",
    "        if state.board.get((x, y)) == 'X':\n",
    "            X_count += 1\n",
    "        elif state.board.get((x, y)) == 'O':\n",
    "            O_count += 1\n",
    "        elif (x, y) in game.obstacles:\n",
    "            obstacle_count += 1\n",
    "    return X_count, O_count, obstacle_count\n",
    "\n",
    "def eval_segment_obstacles(segment, state, player, game):\n",
    "    \"\"\" Returns the evaluation score for a segment \"\"\"\n",
    "    X_count, O_count, obstacle_count = count_in_segment_obstacles(segment, state, game)\n",
    "\n",
    "    if obstacle_count > 0:\n",
    "        return 0\n",
    "    \n",
    "    if X_count > 0 and O_count > 0:\n",
    "        return 0   # mixed segments are neutral\n",
    "\n",
    "    count = max(X_count, O_count)\n",
    "    score = 0\n",
    "\n",
    "    if count == 1:  # open segments with 1 in a row (small chance)\n",
    "        score = 1\n",
    "    elif count == 2:  # open segments with 2 in a row (medium chance)\n",
    "        score = 10\n",
    "    elif count == 3:  # open segments with 3 in a row (big chance)\n",
    "        score = 100\n",
    "    elif count == 4:   # open segments with 4 in a row (game over)\n",
    "        score = 100000\n",
    "\n",
    "    if X_count > O_count:\n",
    "        dominant = 'X'\n",
    "    else:\n",
    "        dominant = 'O'\n",
    "\n",
    "    if dominant == player:\n",
    "        return score\n",
    "    else:\n",
    "        return -score\n",
    "\n",
    "def eval_fn_obstacles(state, player, game):\n",
    "    \"\"\" The evaluation function \"\"\"\n",
    "    total = 0\n",
    "    for segment in all_segments_obstacles:\n",
    "        total += eval_segment_obstacles(segment, state, player, game)\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstacle_list = [(2,3), (5,1), (6,6), (6,1), (6,3), (2,2), (5, 3), (2, 6), (4, 6), (4, 5), (4, 4), (6, 2), (6, 2)]\n",
    "testC4game_obstacles = C4_obstacles(obstacles = obstacle_list)\n",
    "testC4game_obstacles.display(testC4game_obstacles.initial)\n",
    "\n",
    "def obstacles_MC_bot(game, state):\n",
    "    return monte_carlo_tree_search(state, game, N = 1000)\n",
    "\n",
    "def obstacles_alpha_beta_bot(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 5)\n",
    "\n",
    "def obstacles_alpha_beta_eval_bot(game, state):\n",
    "    return alpha_beta_cutoff_search(state, game, d = 5, eval_fn = lambda state, player: eval_fn_obstacles(state, player, game))\n",
    "    # return alpha_beta_cutoff_search(state, game, d = 5, eval_fn = eval_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testC4game_obstacles.play_game(obstacles_MC_bot, obstacles_alpha_beta_eval_bot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_MC_bot_1000' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 129\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Define the bots\u001b[39;00m\n\u001b[0;32m    128\u001b[0m monte_carlo_bots \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 129\u001b[0m     (test_MC_bot_1000, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMC_1000\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    130\u001b[0m     (test_MC_bot_10000, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMC_10000\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    131\u001b[0m     (test_MC_bot_5000, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMC_5000\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m ]\n\u001b[0;32m    134\u001b[0m alpha_beta_bots \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    135\u001b[0m     (test_alpha_beta_bot_4, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAB_4\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    136\u001b[0m     (test_alpha_beta_bot_5, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAB_5\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    137\u001b[0m     (test_alpha_beta_eval_bot_3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAB_3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    138\u001b[0m ]\n\u001b[0;32m    140\u001b[0m alpha_beta_eval_bots \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    141\u001b[0m     (test_alpha_beta_eval_bot_4, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mABE_4\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    142\u001b[0m     (test_alpha_beta_eval_bot_5, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mABE_5\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    143\u001b[0m     (test_alpha_beta_eval_bot_3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mABE_3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_MC_bot_1000' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Function to calculate heuristic score\n",
    "def calculate_heuristic(wins, total_time):\n",
    "    return wins / total_time if total_time > 0 else 0\n",
    "\n",
    "# Simulation cache and results DataFrame\n",
    "simulation_cache = {}\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    \"Bot1\", \"Bot2\", \"Bot1_Wins\", \"Bot2_Wins\", \"Bot1_Time\", \"Bot2_Time\", \"Bot1_Heuristic\", \"Bot2_Heuristic\"\n",
    "])\n",
    "\n",
    "# Function to run simulation and calculate heuristic scores\n",
    "def run_simulation_and_calculate_scores(bot1, bot2, num_games=10):\n",
    "    bot_pair_key = (bot1[1], bot2[1])  # Use bot labels as cache key\n",
    "\n",
    "    # Check if results are already cached\n",
    "    if bot_pair_key in simulation_cache:\n",
    "        return simulation_cache[bot_pair_key]\n",
    "\n",
    "    results = {\"bot1_wins\": 0, \"bot2_wins\": 0, \"bot1_time\": 0, \"bot2_time\": 0}\n",
    "\n",
    "    # Each bot alternates as the starting player for half the games\n",
    "    for i in range(num_games):\n",
    "        if i % 2 == 0:\n",
    "            game_results = run_simulation(1, [(bot1[0], bot1[1]), (bot2[0], bot2[1])])\n",
    "        else:\n",
    "            game_results = run_simulation(1, [(bot2[0], bot2[1]), (bot1[0], bot1[1])])\n",
    "\n",
    "        results[\"bot1_wins\"] += game_results[bot1[1]][\"wins\"]\n",
    "        results[\"bot2_wins\"] += game_results[bot2[1]][\"wins\"]\n",
    "        results[\"bot1_time\"] += game_results[bot1[1]][\"time_per_move\"]\n",
    "        results[\"bot2_time\"] += game_results[bot2[1]][\"time_per_move\"]\n",
    "\n",
    "    bot1_heuristic = calculate_heuristic(results[\"bot1_wins\"], results[\"bot1_time\"])\n",
    "    bot2_heuristic = calculate_heuristic(results[\"bot2_wins\"], results[\"bot2_time\"])\n",
    "\n",
    "    # Cache the results\n",
    "    simulation_cache[bot_pair_key] = (bot1_heuristic, bot2_heuristic)\n",
    "\n",
    "    # Append results to DataFrame\n",
    "    results_df.loc[len(results_df)] = [\n",
    "        bot1[1], bot2[1],\n",
    "        results[\"bot1_wins\"], results[\"bot2_wins\"],\n",
    "        results[\"bot1_time\"], results[\"bot2_time\"],\n",
    "        bot1_heuristic, bot2_heuristic\n",
    "    ]\n",
    "    \n",
    "    return bot1_heuristic, bot2_heuristic\n",
    "\n",
    "# Function to create heuristic matrix and format as DataFrame\n",
    "def create_heuristic_matrix_df(bots, opponents):\n",
    "    bot_names = [bot[1] for bot in bots]\n",
    "    opponent_names = [opponent[1] for opponent in opponents]\n",
    "\n",
    "    # Initialize matrix with zeros\n",
    "    matrix = np.zeros((len(bots), len(opponents) + 1))\n",
    "\n",
    "    for i, bot in enumerate(bots):\n",
    "        total_heuristic = 0\n",
    "        for j, opponent in enumerate(opponents):\n",
    "            if bot != opponent:\n",
    "                bot_heuristic, _ = run_simulation_and_calculate_scores(bot, opponent)\n",
    "                matrix[i, j] = bot_heuristic\n",
    "                total_heuristic += bot_heuristic\n",
    "\n",
    "        # Calculate average heuristic score\n",
    "        if len(opponents) > 0:\n",
    "            matrix[i, -1] = total_heuristic / len(opponents)\n",
    "\n",
    "    # Create DataFrame with column headers\n",
    "    column_headers = opponent_names + [\"Average\"]\n",
    "    heuristic_df = pd.DataFrame(matrix, columns=column_headers)\n",
    "    heuristic_df.insert(0, \"Bot\", bot_names)  # Insert bot names as the first column\n",
    "\n",
    "    return heuristic_df\n",
    "\n",
    "# Function to run a simulation of games\n",
    "def run_simulation(num_games, bot_functions_with_labels):\n",
    "    results = {label: {\"wins\": 0, \"total_time\": 0, \"total_moves\": 0} for _, label in bot_functions_with_labels}\n",
    "    bot_order = deque([bot for bot, _ in bot_functions_with_labels])\n",
    "    label_order = deque([label for _, label in bot_functions_with_labels])\n",
    "\n",
    "    for i in range(num_games):\n",
    "        bot_order.rotate(-1)\n",
    "        label_order.rotate(-1)\n",
    "        X_bot, O_bot = bot_order\n",
    "        X_label, O_label = label_order\n",
    "        game = C4(h=6, v=7, k=4)\n",
    "        state = game.initial\n",
    "        current_player = 'X'\n",
    "        game_over = False\n",
    "        player_to_bot = {'X': X_bot, 'O': O_bot}\n",
    "        player_to_label = {'X': X_label, 'O': O_label}\n",
    "\n",
    "        while not game_over:\n",
    "            bot = player_to_bot[current_player]\n",
    "            start_time = time.time()\n",
    "            move = bot(game, state)\n",
    "            state = game.result(state, move)\n",
    "            move_time = time.time() - start_time\n",
    "            bot_label = player_to_label[current_player]\n",
    "            results[bot_label][\"total_time\"] += move_time\n",
    "            results[bot_label][\"total_moves\"] += 1\n",
    "\n",
    "            if game.terminal_test(state):\n",
    "                winner = game.utility(state, game.to_move(game.initial))\n",
    "                if winner == 1:\n",
    "                    results[X_label][\"wins\"] += 1\n",
    "                elif winner == -1:\n",
    "                    results[O_label][\"wins\"] += 1\n",
    "                game_over = True\n",
    "\n",
    "            current_player = 'O' if current_player == 'X' else 'X'\n",
    "\n",
    "    for bot in results:\n",
    "        if results[bot][\"total_moves\"] > 0:\n",
    "            results[bot][\"time_per_move\"] = results[bot][\"total_time\"] / results[bot][\"total_moves\"]\n",
    "        else:\n",
    "            results[bot][\"time_per_move\"] = 0\n",
    "\n",
    "    return results\n",
    "\n",
    "# Define the bots\n",
    "monte_carlo_bots = [\n",
    "    (test_MC_bot_1000, \"MC_1000\"),\n",
    "    (test_MC_bot_10000, \"MC_10000\"),\n",
    "    (test_MC_bot_5000, \"MC_5000\")\n",
    "]\n",
    "\n",
    "alpha_beta_bots = [\n",
    "    (test_alpha_beta_bot_4, \"AB_4\"),\n",
    "    (test_alpha_beta_bot_5, \"AB_5\"),\n",
    "    (test_alpha_beta_eval_bot_3, \"AB_3\")\n",
    "]\n",
    "\n",
    "alpha_beta_eval_bots = [\n",
    "    (test_alpha_beta_eval_bot_4, \"ABE_4\"),\n",
    "    (test_alpha_beta_eval_bot_5, \"ABE_5\"),\n",
    "    (test_alpha_beta_eval_bot_3, \"ABE_3\")\n",
    "]\n",
    "\n",
    "# Create matrices for each type of bots\n",
    "monte_carlo_df = create_heuristic_matrix_df(monte_carlo_bots, alpha_beta_bots + alpha_beta_eval_bots)\n",
    "alpha_beta_df = create_heuristic_matrix_df(alpha_beta_bots, monte_carlo_bots + alpha_beta_eval_bots)\n",
    "alpha_beta_eval_df = create_heuristic_matrix_df(alpha_beta_eval_bots, monte_carlo_bots + alpha_beta_bots)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nMonte Carlo Bots Heuristic Matrix:\")\n",
    "print(monte_carlo_df)\n",
    "\n",
    "print(\"\\nAlpha Beta Bots Heuristic Matrix:\")\n",
    "print(alpha_beta_df)\n",
    "\n",
    "print(\"\\nAlpha Beta Eval Bots Heuristic Matrix:\")\n",
    "print(alpha_beta_eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def _init_(self, actions, alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01):\n",
    "        self.actions = actions  # List of valid actions (which are tuples (x, y), where y is the column)\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.epsilon_decay = epsilon_decay  # Decay rate for exploration\n",
    "        self.epsilon_min = epsilon_min  # Minimum exploration rate\n",
    "        \n",
    "        # Initialize Q-table (state-action pair => Q-value)\n",
    "        self.q_table = defaultdict(lambda: np.zeros(len(actions)))\n",
    "\n",
    "    def get_action(self, state, valid_actions):\n",
    "        \"\"\"Choose an action using epsilon-greedy policy.\"\"\"\n",
    "        if random.uniform(0, 1) < self.epsilon:  # Exploration\n",
    "            return random.choice(valid_actions)\n",
    "        else:  # Exploitation\n",
    "            state_tuple = self._get_state_tuple(state)\n",
    "            \n",
    "            # Extract column indices from (x, y) tuples in valid_actions\n",
    "            valid_column_indices = [y - 1 for _, y in valid_actions]  # Convert to 0-based column indices\n",
    "            q_values = self.q_table[state_tuple][valid_column_indices]  # Access the Q-values of valid actions\n",
    "            best_action_idx = np.argmax(q_values)\n",
    "            \n",
    "            # Return the action corresponding to the best Q-value\n",
    "            return valid_actions[best_action_idx]\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state, valid_actions):\n",
    "        \"\"\"Update Q-value using the Q-learning update rule.\"\"\"\n",
    "        state_tuple = self._get_state_tuple(state)\n",
    "        next_state_tuple = self._get_state_tuple(next_state)\n",
    "        \n",
    "        # Extract column indices from (x, y) tuples in valid_actions\n",
    "        valid_column_indices = [y - 1 for _, y in valid_actions]  # Convert to 0-based column indices\n",
    "        \n",
    "        # Find the best possible future Q-value from valid actions in the next state\n",
    "        future_q = np.max(self.q_table[next_state_tuple][valid_column_indices])\n",
    "        \n",
    "        # Get the action's current Q-value (using the column index from the action)\n",
    "        action_column_index = action[1] - 1  # Extract column index and adjust to 0-based\n",
    "        current_q = self.q_table[state_tuple][action_column_index]\n",
    "        \n",
    "        # Q-learning update rule\n",
    "        self.q_table[state_tuple][action_column_index] = current_q + self.alpha * (reward + self.gamma * future_q - current_q)\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        \"\"\"Decay epsilon to reduce exploration over time.\"\"\"\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "    def _get_state_tuple(self, state):\n",
    "        \"\"\"Convert the board state to a tuple to use as a dictionary key.\"\"\"\n",
    "        return tuple(sorted(state.board.keys()))  # Use sorted keys as a simple hashablerepresentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def train(agent, game, episodes):\n",
    "    # Example of epsilon decay (in training loop):\n",
    "    epsilon = 1.0  # Start with full exploration\n",
    "    epsilon_min = 0.1  # Minimum value for epsilon\n",
    "    epsilon_decay = 0.995  # Decay rate\n",
    "\n",
    "# In your training loop, decay epsilon after each episode\n",
    "    for episode in range(episodes):\n",
    "        state = game.initial\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            valid_actions = game.actions(state)\n",
    "            action = agent.get_action(state, valid_actions)  # Agent's move\n",
    "        \n",
    "            next_state = game.result(state, action)  # Apply the move\n",
    "            reward = next_state.utility if game.terminal_test(next_state) else 0  # Reward calculation\n",
    "            total_reward += reward\n",
    "\n",
    "        # Update the Q-table\n",
    "            agent.update_q_value(state, action, reward, next_state, valid_actions)\n",
    "        \n",
    "        # Decay epsilon\n",
    "            epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "            state = next_state\n",
    "        \n",
    "            if game.terminal_test(state):\n",
    "                episode_rewards.append(total_reward)\n",
    "            #print(f\"Episode {episode+1} finished. Reward: {total_reward}\")\n",
    "\n",
    "        print(\"Finishedtraining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "game = C4()  # Create a Connect 4 game\n",
    "actions = list(range(1, game.v + 1))  # List of valid columns (1 to 7)\n",
    "agent = QLearningAgent(actions)  # Initialize the Q-learning agent\n",
    "\n",
    "train(agent, game, episodes=10000)  # Train the agent for1000episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = game.initial\n",
    "state_tuple = agent._get_state_tuple(state)\n",
    "\n",
    "# Print the Q-values for the initial state\n",
    "print(f\"Q-values for state {state_tuple}: {agent.q_table[state_tuple]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
